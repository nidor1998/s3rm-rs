# Task 29: Automated E2E Integration Testing

> **Referenced from**: `steering/init_build/tasks.md` (Task 29)
> **Status**: Not yet started

## E2E Test Requirements Checklist

- [ ] Tests use `#![cfg(e2e_test)]` attribute (compiled only with `RUSTFLAGS="--cfg e2e_test"`)
- [ ] All tests use the AWS profile `s3rm-e2e-test` (via `--target-profile s3rm-e2e-test`)
- [ ] All E2E tests are executable in parallel (no shared state between tests; each test has a unique bucket)
- [ ] Tests invoke the s3rm-rs library API (`build_config_from_args` + `DeletionPipeline`) -- not the CLI binary
- [ ] Maximize source code coverage across all test cases
- [ ] Test both Lua callbacks and Rust callbacks
- [ ] No network disconnection/failure tests, BUT access denial tests ARE required
- [ ] Bucket names are randomly generated per test case (use UUID v4 prefix: `s3rm-e2e-{uuid}`)
- [ ] Post-processing ALWAYS runs regardless of test success/failure: delete all objects + delete bucket
- [ ] Test data is auto-generated by the tests and uploaded to the target bucket (few KB per object, sufficient count)
- [ ] Tests may use AWS SDK directly for test preparation (creating buckets, uploading objects, enabling versioning)
- [ ] No performance testing in E2E tests
- [ ] All CLI options tested; filtering options individually (one test per filter type); other options grouped logically
- [ ] Maximum 1000 objects per E2E test case
- [ ] Each test function name must be descriptive and clearly convey what is being tested
- [ ] Each test function MUST begin with a detailed comment block explaining: (1) the purpose of the test, (2) the test setup, (3) the expected results. This is required for human review.

## E2E Test Infrastructure

- [ ] 29.0 Create shared test helper module (`tests/common/mod.rs`)
  - `TestHelper` struct wrapping an S3 `Client` built with profile `s3rm-e2e-test`
  - `create_bucket(bucket)` -- creates a standard S3 bucket
  - `create_versioned_bucket(bucket)` -- creates bucket + enables versioning
  - `delete_bucket_cascade(bucket)` -- deletes all objects/versions + deletes bucket (always runs in cleanup)
  - `put_object(bucket, key, body)` -- uploads an object with given body bytes
  - `put_object_with_content_type(bucket, key, body, content_type)` -- uploads with explicit content type
  - `put_object_with_metadata(bucket, key, body, metadata: HashMap)` -- uploads with user-defined metadata
  - `put_object_with_tags(bucket, key, body, tags: HashMap)` -- uploads with tagging
  - `list_objects(bucket, prefix) -> Vec<String>` -- lists remaining object keys (for assertions)
  - `list_object_versions(bucket) -> Vec<(String, String)>` -- lists version IDs (for versioning assertions)
  - `count_objects(bucket, prefix) -> usize` -- counts objects remaining after deletion
  - `generate_bucket_name() -> String` -- returns `s3rm-e2e-{uuid}` for test isolation
  - `build_config(args: Vec<&str>) -> Config` -- calls `build_config_from_args` with common defaults prepended
  - `run_pipeline(config: Config) -> PipelineResult` -- creates token, runs pipeline, returns stats + error state
  - `init_tracing()` -- initializes a dummy tracing subscriber for test output
  - `PipelineResult` struct: `stats: DeletionStats`, `has_error: bool`, `has_warning: bool`, `errors: Vec<String>`
  - Region constant: use region from the `s3rm-e2e-test` profile (e.g., `us-east-1`)
  - All helper methods are `async` and use `tokio`

## E2E Test Plan: Filtering Tests (one test per filter type)

Each filtering test uploads ~20 objects with varying properties, runs the pipeline with the specified filter, and asserts that only matching objects were deleted while non-matching objects remain.

- [ ] 29.1 `e2e_filter_include_regex`
  - **Tests**: `--filter-include-regex`
  - **Setup**: Upload 20 objects: 10 with keys matching `^logs/.*\.txt$`, 10 with keys like `data/file.csv`
  - **Config**: `--filter-include-regex "^logs/.*\\.txt$" --force`
  - **Assertions**: Only the 10 `logs/*.txt` objects deleted; 10 `data/` objects remain
  - _Requirements: 2.2_

- [ ] 29.2 `e2e_filter_exclude_regex`
  - **Tests**: `--filter-exclude-regex`
  - **Setup**: Upload 20 objects: 10 with keys matching `^keep/`, 10 with keys like `delete/file.dat`
  - **Config**: `--filter-exclude-regex "^keep/" --force`
  - **Assertions**: 10 `delete/` objects deleted; 10 `keep/` objects remain
  - _Requirements: 2.2_

- [ ] 29.3 `e2e_filter_include_content_type_regex`
  - **Tests**: `--filter-include-content-type-regex`
  - **Setup**: Upload 10 objects with `Content-Type: text/plain`, 10 with `Content-Type: application/json`
  - **Config**: `--filter-include-content-type-regex "text/plain" --force`
  - **Assertions**: 10 text/plain objects deleted; 10 application/json objects remain
  - _Requirements: 2.3_

- [ ] 29.4 `e2e_filter_exclude_content_type_regex`
  - **Tests**: `--filter-exclude-content-type-regex`
  - **Setup**: Upload 10 objects with `Content-Type: image/png`, 10 with `Content-Type: text/html`
  - **Config**: `--filter-exclude-content-type-regex "image/png" --force`
  - **Assertions**: 10 text/html objects deleted; 10 image/png objects remain
  - _Requirements: 2.3_

- [ ] 29.5 `e2e_filter_include_metadata_regex`
  - **Tests**: `--filter-include-metadata-regex`
  - **Setup**: Upload 10 objects with metadata `env=production`, 10 with metadata `env=staging`
  - **Config**: `--filter-include-metadata-regex "env=production" --force`
  - **Assertions**: 10 `env=production` objects deleted; 10 `env=staging` objects remain
  - _Requirements: 2.4_

- [ ] 29.6 `e2e_filter_exclude_metadata_regex`
  - **Tests**: `--filter-exclude-metadata-regex`
  - **Setup**: Upload 10 objects with metadata `tier=archive`, 10 with metadata `tier=hot`
  - **Config**: `--filter-exclude-metadata-regex "tier=archive" --force`
  - **Assertions**: 10 `tier=hot` objects deleted; 10 `tier=archive` objects remain
  - _Requirements: 2.4_

- [ ] 29.6a `e2e_filter_include_metadata_regex_multiple_entries`
  - **Tests**: `--filter-include-metadata-regex` with 3+ metadata entries per object
  - **Setup**: Upload 20 objects: 10 with metadata `{env=production, team=backend, version=v2}`, 10 with metadata `{env=staging, team=frontend, version=v1}`. Metadata is serialized sorted: `env=production,team=backend,version=v2`
  - **Config**: `--filter-include-metadata-regex "env=production,team=backend,version=v2" --force`
  - **Assertions**: 10 `env=production` objects deleted (regex matches full sorted entry); 10 `env=staging` objects remain
  - _Requirements: 2.4_

- [ ] 29.6b `e2e_filter_exclude_metadata_regex_multiple_entries_alternation`
  - **Tests**: `--filter-exclude-metadata-regex` with spec alternation pattern `"key1=(value1|value2),key2=value2"`
  - **Setup**: Upload 30 objects: 10 with `{env=production, team=backend, version=v2}`, 10 with `{env=staging, team=backend, version=v2}`, 10 with `{env=development, team=frontend, version=v1}`
  - **Config**: `--filter-exclude-metadata-regex "env=(production|staging),team=backend" --force`
  - **Assertions**: 10 `dev/` objects deleted; 10 `prod/` and 10 `staging/` remain (excluded by alternation regex)
  - _Requirements: 2.4_

- [ ] 29.7 `e2e_filter_include_tag_regex`
  - **Tests**: `--filter-include-tag-regex`
  - **Setup**: Upload 10 objects tagged `status=expired`, 10 tagged `status=active`
  - **Config**: `--filter-include-tag-regex "status=expired" --force`
  - **Assertions**: 10 `status=expired` objects deleted; 10 `status=active` objects remain
  - _Requirements: 2.5_

- [ ] 29.8 `e2e_filter_exclude_tag_regex`
  - **Tests**: `--filter-exclude-tag-regex`
  - **Setup**: Upload 10 objects tagged `retain=true`, 10 tagged `retain=false`
  - **Config**: `--filter-exclude-tag-regex "retain=true" --force`
  - **Assertions**: 10 `retain=false` objects deleted; 10 `retain=true` objects remain
  - _Requirements: 2.5_

- [ ] 29.8a `e2e_filter_include_tag_regex_multiple_tags`
  - **Tests**: `--filter-include-tag-regex` with 3+ tags per object
  - **Setup**: Upload 20 objects: 10 tagged `{env=production, retain=false, team=backend}`, 10 tagged `{env=staging, retain=true, team=frontend}`. Tags are serialized sorted and `&`-separated: `env=production&retain=false&team=backend`
  - **Config**: `--filter-include-tag-regex "env=production&retain=false&team=backend" --force`
  - **Assertions**: 10 `env=production` objects deleted (regex matches full sorted tag entry); 10 `env=staging` objects remain
  - _Requirements: 2.5_

- [ ] 29.8b `e2e_filter_exclude_tag_regex_multiple_tags_alternation`
  - **Tests**: `--filter-exclude-tag-regex` with spec alternation pattern `"key1=(value1|value2)&key2=value2"`
  - **Setup**: Upload 30 objects: 10 tagged `{env=production, retain=true, team=backend}`, 10 tagged `{env=staging, retain=true, team=backend}`, 10 tagged `{env=development, retain=false, team=frontend}`
  - **Config**: `--filter-exclude-tag-regex "env=(production|staging)&retain=true" --force`
  - **Assertions**: 10 `dev/` objects deleted; 10 `prod/` and 10 `staging/` remain (excluded by alternation regex)
  - _Requirements: 2.5_

- [ ] 29.9 `e2e_filter_mtime_before`
  - **Tests**: `--filter-mtime-before`
  - **Setup**: Upload 10 objects now. Then upload 10 more objects. Record a timestamp `T` between the two batches.
  - **Config**: `--filter-mtime-before <T in RFC 3339> --force`
  - **Assertions**: Only the first 10 (older) objects deleted; newer 10 remain
  - **Note**: Need a sleep or known timestamp between batches to reliably separate them
  - _Requirements: 2.7_

- [ ] 29.10 `e2e_filter_mtime_after`
  - **Tests**: `--filter-mtime-after`
  - **Setup**: Same as 29.9 with timestamp `T` between two batches
  - **Config**: `--filter-mtime-after <T in RFC 3339> --force`
  - **Assertions**: Only the second 10 (newer) objects deleted; older 10 remain
  - _Requirements: 2.7_

- [ ] 29.11 `e2e_filter_smaller_size`
  - **Tests**: `--filter-smaller-size`
  - **Setup**: Upload 10 objects of 100 bytes each, 10 objects of 10KB each
  - **Config**: `--filter-smaller-size 1KB --force`
  - **Assertions**: 10 small (100B) objects deleted; 10 large (10KB) objects remain
  - _Requirements: 2.6_

- [ ] 29.12 `e2e_filter_larger_size`
  - **Tests**: `--filter-larger-size`
  - **Setup**: Upload 10 objects of 100 bytes each, 10 objects of 10KB each
  - **Config**: `--filter-larger-size 1KB --force`
  - **Assertions**: 10 large (10KB) objects deleted; 10 small (100B) objects remain
  - _Requirements: 2.6_

## E2E Test Plan: Core Deletion Mode Tests

- [ ] 29.13 `e2e_basic_prefix_deletion`
  - **Tests**: Basic deletion by prefix (positional `target` argument)
  - **Setup**: Upload 30 objects under prefix `data/`, 10 objects under prefix `other/`
  - **Config**: `s3://{bucket}/data/ --force`
  - **Assertions**: All 30 `data/` objects deleted; 10 `other/` objects remain; stats show 30 deleted, 0 failed
  - _Requirements: 1.1, 2.1_

- [ ] 29.14 `e2e_batch_deletion_mode`
  - **Tests**: Batch deletion with default batch size (200), `--batch-size` option
  - **Setup**: Upload 500 objects under a single prefix
  - **Config**: `--batch-size 100 --force`
  - **Assertions**: All 500 objects deleted; stats show 500 deleted, 0 failed
  - _Requirements: 1.1, 1.9_

- [ ] 29.15 `e2e_single_deletion_mode`
  - **Tests**: Single-object deletion mode (`--batch-size 1`)
  - **Setup**: Upload 20 objects
  - **Config**: `--batch-size 1 --force`
  - **Assertions**: All 20 objects deleted; stats show 20 deleted, 0 failed
  - _Requirements: 1.2_

- [ ] 29.16 `e2e_delete_entire_bucket_contents`
  - **Tests**: Deleting all objects in a bucket (no prefix)
  - **Setup**: Upload 50 objects with varied prefixes (`a/`, `b/`, `c/`, root-level)
  - **Config**: `s3://{bucket} --force` (no prefix -- deletes everything)
  - **Assertions**: All 50 objects deleted; bucket is empty; stats show 50 deleted
  - _Requirements: 2.10_

- [ ] 29.17 `e2e_empty_bucket_no_error`
  - **Tests**: Running against an empty bucket should complete without error
  - **Setup**: Create empty bucket (no objects)
  - **Config**: `s3://{bucket} --force`
  - **Assertions**: Pipeline completes without error; stats show 0 deleted, 0 failed
  - _Requirements: 1.8_

## E2E Test Plan: Safety Feature Tests

- [ ] 29.18 `e2e_dry_run_no_deletion`
  - **Tests**: `--dry-run` flag prevents actual deletions
  - **Setup**: Upload 20 objects
  - **Config**: `--dry-run --force`
  - **Assertions**: All 20 objects still exist after pipeline; stats show 20 "deleted" (simulated); no S3 deletions occurred
  - _Requirements: 3.1_

- [ ] 29.19 `e2e_max_delete_threshold`
  - **Tests**: `--max-delete` stops deletion after threshold
  - **Setup**: Upload 50 objects
  - **Config**: `--max-delete 10 --force`
  - **Assertions**: Exactly 10 objects deleted; 40 remain; pipeline reports cancellation or partial completion
  - _Requirements: 3.6_

- [ ] 29.20 `e2e_force_flag_skips_confirmation`
  - **Tests**: `--force` flag (pipeline runs without prompt in library API; this test confirms force=true works)
  - **Setup**: Upload 10 objects
  - **Config**: `--force`
  - **Assertions**: All 10 objects deleted; no prompt interaction required
  - _Requirements: 3.4, 13.2_

## E2E Test Plan: Versioning Tests

- [ ] 29.21 `e2e_versioned_bucket_creates_delete_markers`
  - **Tests**: Deleting from versioned bucket without `--delete-all-versions` creates delete markers
  - **Setup**: Create versioned bucket; upload 10 objects (creates initial versions)
  - **Config**: `--force` (no `--delete-all-versions`)
  - **Assertions**: Delete markers created; original versions still exist; `list_object_versions` shows both markers and original versions
  - _Requirements: 5.1_

- [ ] 29.22 `e2e_delete_all_versions`
  - **Tests**: `--delete-all-versions` deletes all versions including delete markers
  - **Setup**: Create versioned bucket; upload 10 objects; overwrite each object once (creates 2 versions each); delete some (creates delete markers)
  - **Config**: `--delete-all-versions --force`
  - **Assertions**: No object versions or delete markers remain; bucket is completely clean; stats count each version/marker as a separate deletion
  - _Requirements: 5.2, 5.4_

- [ ] 29.23 `e2e_delete_all_versions_unversioned_bucket_error`
  - **Tests**: `--delete-all-versions` on a non-versioned bucket produces an error
  - **Setup**: Create standard (non-versioned) bucket; upload 5 objects
  - **Config**: `--delete-all-versions --force`
  - **Assertions**: Pipeline reports error about versioning requirement; no objects deleted
  - _Requirements: 5.2_

## E2E Test Plan: Callback Tests

- [ ] 29.24 `e2e_rust_filter_callback`
  - **Tests**: Registering a Rust `FilterCallback` via `config.filter_manager.register_callback()`
  - **Setup**: Upload 20 objects: 10 with keys starting with `keep-`, 10 with keys starting with `delete-`
  - **Config**: Build config with `--force`; register a Rust filter callback that returns `true` only for keys starting with `delete-`
  - **Assertions**: 10 `delete-` objects removed; 10 `keep-` objects remain
  - _Requirements: 2.9, 12.5_

- [ ] 29.25 `e2e_rust_event_callback`
  - **Tests**: Registering a Rust `EventCallback` via `config.event_manager.register_callback()`
  - **Setup**: Upload 10 objects
  - **Config**: Build config with `--force`; register a Rust event callback with `EventType::ALL_EVENTS` that collects events into an `Arc<Mutex<Vec<EventData>>>`
  - **Assertions**: Callback received `PIPELINE_START`, `DELETE_COMPLETE` (10 times), and `PIPELINE_END` events; event data includes correct keys and sizes
  - _Requirements: 7.6, 7.7, 12.6_

- [ ] 29.26 `e2e_lua_filter_callback`
  - **Tests**: `--filter-callback-lua-script` with a Lua filter script
  - **Setup**: Upload 20 objects: 10 with `.tmp` extension, 10 with `.dat` extension. Write a temporary Lua filter script that returns `true` for keys ending in `.tmp`
  - **Config**: `--filter-callback-lua-script <path> --force`
  - **Assertions**: 10 `.tmp` objects deleted; 10 `.dat` objects remain
  - _Requirements: 2.8, 2.12_

- [ ] 29.27 `e2e_lua_event_callback`
  - **Tests**: `--event-callback-lua-script` with a Lua event script
  - **Setup**: Upload 10 objects. Write a temporary Lua event script that writes event counts to a temp file (using `allow_lua_os_library`)
  - **Config**: `--event-callback-lua-script <path> --allow-lua-os-library --force`
  - **Assertions**: All 10 objects deleted; the Lua output file contains expected event records
  - _Requirements: 2.12, 7.6_

- [ ] 29.28 `e2e_lua_sandbox_blocks_os_access`
  - **Tests**: Default Lua sandbox blocks OS library access
  - **Setup**: Upload 5 objects. Write a Lua filter script that calls `os.execute("echo test")`
  - **Config**: `--filter-callback-lua-script <path> --force` (no `--allow-lua-os-library`)
  - **Assertions**: Pipeline reports error (Lua sandbox violation); objects may or may not be deleted depending on when the error occurs
  - _Requirements: 2.13_

- [ ] 29.29 `e2e_lua_vm_memory_limit`
  - **Tests**: `--lua-vm-memory-limit` enforces Lua memory cap
  - **Setup**: Upload 5 objects. Write a Lua filter script that allocates a large table (exceeding 1MB)
  - **Config**: `--filter-callback-lua-script <path> --lua-vm-memory-limit 1MB --force`
  - **Assertions**: Pipeline reports error or process terminates due to Lua memory limit exceeded
  - _Requirements: 2.14_

- [ ] 29.30 `e2e_rust_filter_and_event_callbacks_combined`
  - **Tests**: Using both Rust filter and event callbacks simultaneously
  - **Setup**: Upload 20 objects: 10 large (5KB), 10 small (100B)
  - **Config**: Register a Rust filter callback (delete only objects >= 1KB); register a Rust event callback collecting events
  - **Assertions**: 10 large objects deleted; 10 small remain; event callback received DELETE_COMPLETE for each deleted object and DELETE_FILTERED for each skipped object
  - _Requirements: 2.9, 7.6, 12.5, 12.6_

## E2E Test Plan: Optimistic Locking Tests

- [ ] 29.31 `e2e_if_match_single_deletion`
  - **Tests**: `--if-match` flag with single deletion mode (`--batch-size 1`)
  - **Setup**: Upload 10 objects
  - **Config**: `--if-match --batch-size 1 --force`
  - **Assertions**: All 10 objects deleted (ETags match since objects not modified between list and delete); stats show 10 deleted, 0 failed
  - _Requirements: 11.1, 11.3_

- [ ] 29.32 `e2e_if_match_batch_deletion`
  - **Tests**: `--if-match` flag with batch deletion mode
  - **Setup**: Upload 20 objects
  - **Config**: `--if-match --batch-size 10 --force`
  - **Assertions**: All 20 objects deleted; ETags match for unmodified objects
  - _Requirements: 11.1, 11.4_

- [ ] 29.32a `e2e_if_match_etag_mismatch_skips_modified_objects`
  - **Tests**: `--if-match` flag correctly skips objects modified after listing (ETag mismatch)
  - **Setup**: Upload 10 objects. Register a Rust filter callback that, during filtering, overwrites 3 specific objects with new content (changing their ETags) via the AWS SDK, then returns `true` for all objects
  - **Config**: `--if-match --batch-size 1 --force` (single deletion mode for clearer per-object behavior)
  - **Assertions**: 7 unmodified objects deleted; 3 modified objects remain (ETag mismatch causes skip); stats show 7 deleted; `has_warning` is true or error count reflects the 3 mismatches; objects that were modified still exist in the bucket
  - _Requirements: 11.2_

## E2E Test Plan: Performance Option Tests

- [ ] 29.33 `e2e_worker_size_configuration`
  - **Tests**: `--worker-size` with different values
  - **Setup**: Upload 100 objects
  - **Config**: `--worker-size 4 --force`
  - **Assertions**: All 100 objects deleted; stats show 100 deleted
  - _Requirements: 1.3, 1.4_

- [ ] 29.34 `e2e_rate_limit_objects`
  - **Tests**: `--rate-limit-objects` rate limiting
  - **Setup**: Upload 50 objects
  - **Config**: `--rate-limit-objects 200 --force` (200 obj/sec -- slow but should complete)
  - **Assertions**: All 50 objects deleted; pipeline completes (rate limiting does not prevent completion)
  - _Requirements: 8.7, 8.8_

- [ ] 29.35 `e2e_max_parallel_listings`
  - **Tests**: `--max-parallel-listings` and `--max-parallel-listing-max-depth`
  - **Setup**: Upload 100 objects with varied prefixes (5 different top-level prefixes, 20 objects each)
  - **Config**: `--max-parallel-listings 2 --max-parallel-listing-max-depth 1 --force`
  - **Assertions**: All 100 objects deleted; parallel listing configuration did not cause errors
  - _Requirements: 1.5, 1.6, 1.7_

- [ ] 29.36 `e2e_object_listing_queue_size`
  - **Tests**: `--object-listing-queue-size`
  - **Setup**: Upload 50 objects
  - **Config**: `--object-listing-queue-size 5 --force`
  - **Assertions**: All 50 objects deleted (small queue size does not prevent completion)
  - _Requirements: 1.8_

- [ ] 29.37 `e2e_max_keys_listing`
  - **Tests**: `--max-keys` controls objects per list request
  - **Setup**: Upload 100 objects
  - **Config**: `--max-keys 10 --force` (forces pagination with 10 objects per page)
  - **Assertions**: All 100 objects deleted (pagination with small page size works correctly)
  - _Requirements: 1.5_

## E2E Test Plan: Tracing and Logging Tests

- [ ] 29.38 `e2e_verbosity_levels`
  - **Tests**: `-v`, `-vv`, `-vvv` verbosity flags (grouped test)
  - **Setup**: Upload 5 objects
  - **Config**: Run 3 times with `-v`, `-vv`, `-vvv` respectively, all with `--force`
  - **Assertions**: All 5 objects deleted in each run; no errors; pipeline completes (logging configuration does not affect functionality)
  - _Requirements: 4.1, 4.2, 4.3, 4.4, 4.5_

- [ ] 29.39 `e2e_json_tracing`
  - **Tests**: `--json-tracing` (requires `--force`)
  - **Setup**: Upload 5 objects
  - **Config**: `--json-tracing --force`
  - **Assertions**: Pipeline completes; all 5 objects deleted
  - _Requirements: 4.7, 13.3_

- [ ] 29.40 `e2e_quiet_mode`
  - **Tests**: `-q` (quiet mode) suppresses progress
  - **Setup**: Upload 5 objects
  - **Config**: `-q --force`
  - **Assertions**: Pipeline completes; all 5 objects deleted
  - _Requirements: 7.4_

- [ ] 29.41 `e2e_show_no_progress`
  - **Tests**: `--show-no-progress` hides progress bar
  - **Setup**: Upload 5 objects
  - **Config**: `--show-no-progress --force`
  - **Assertions**: Pipeline completes; all 5 objects deleted
  - _Requirements: 7.4_

- [ ] 29.42 `e2e_disable_color_tracing`
  - **Tests**: `--disable-color-tracing`
  - **Setup**: Upload 5 objects
  - **Config**: `--disable-color-tracing --force`
  - **Assertions**: Pipeline completes; all 5 objects deleted
  - _Requirements: 4.8, 4.9_

- [ ] 29.43 `e2e_log_deletion_summary`
  - **Tests**: `--log-deletion-summary`
  - **Setup**: Upload 10 objects
  - **Config**: `--log-deletion-summary --force`
  - **Assertions**: Pipeline completes; all 10 objects deleted; stats logged
  - _Requirements: 7.3_

- [ ] 29.44 `e2e_aws_sdk_tracing_and_span_events`
  - **Tests**: `--aws-sdk-tracing` and `--span-events-tracing` (grouped)
  - **Setup**: Upload 5 objects
  - **Config**: `--aws-sdk-tracing --span-events-tracing -vvv --force`
  - **Assertions**: Pipeline completes; all 5 objects deleted; AWS SDK trace events produced
  - _Requirements: 4.5_

## E2E Test Plan: Retry and Timeout Option Tests

- [ ] 29.45 `e2e_retry_options`
  - **Tests**: `--aws-max-attempts`, `--initial-backoff-milliseconds`, `--force-retry-count`, `--force-retry-interval-milliseconds`
  - **Setup**: Upload 10 objects
  - **Config**: `--aws-max-attempts 2 --initial-backoff-milliseconds 100 --force-retry-count 1 --force-retry-interval-milliseconds 100 --force`
  - **Assertions**: Pipeline completes; all 10 objects deleted (retry options do not prevent normal operation)
  - _Requirements: 6.1, 6.2_

- [ ] 29.46 `e2e_timeout_options`
  - **Tests**: `--operation-timeout-milliseconds`, `--operation-attempt-timeout-milliseconds`, `--connect-timeout-milliseconds`, `--read-timeout-milliseconds`
  - **Setup**: Upload 10 objects
  - **Config**: `--operation-timeout-milliseconds 30000 --connect-timeout-milliseconds 5000 --read-timeout-milliseconds 5000 --force`
  - **Assertions**: Pipeline completes within timeout; all 10 objects deleted
  - _Requirements: 8.3_

- [ ] 29.47 `e2e_disable_stalled_stream_protection`
  - **Tests**: `--disable-stalled-stream-protection`
  - **Setup**: Upload 10 objects
  - **Config**: `--disable-stalled-stream-protection --force`
  - **Assertions**: Pipeline completes; all 10 objects deleted
  - _Requirements: 8.3_

## E2E Test Plan: Error Handling and Access Denial Tests

- [ ] 29.48 `e2e_access_denied_invalid_credentials`
  - **Tests**: Access denial with invalid AWS credentials
  - **Setup**: Create a standard bucket and upload 5 objects (using valid credentials for setup)
  - **Config**: Build config with `--target-access-key INVALID --target-secret-access-key INVALID --target-region us-east-1 --force -v`
  - **Assertions**: Pipeline reports error; `has_error()` returns true; error type is AWS SDK error (access denied or invalid credentials); error message includes error code (validates that failures are logged with error message and code)
  - _Requirements: 4.10, 6.4, 10.5, 13.4_

- [ ] 29.49 `e2e_nonexistent_bucket_error`
  - **Tests**: Deleting from a bucket that does not exist
  - **Setup**: No bucket creation (use a random non-existent bucket name)
  - **Config**: `s3://s3rm-e2e-nonexistent-{uuid}/ --force`
  - **Assertions**: Pipeline reports error (NoSuchBucket or similar); `has_error()` returns true
  - _Requirements: 6.4, 10.5_

- [ ] 29.49a `e2e_batch_partial_failure_access_denied`
  - **Tests**: Batch deletion partial failure when some objects are protected by a deny bucket policy
  - **Setup**: Upload 20 objects: 10 under `deletable/`, 10 under `protected/`. Apply a bucket policy denying `s3:DeleteObject` on `protected/*`
  - **Config**: `s3://{bucket}/ --force`
  - **Assertions**: 10 `deletable/` objects deleted; 10 `protected/` objects remain (AccessDenied); stats show ~10 deleted, ~10 failed; pipeline reports warning or error
  - **Cleanup**: Remove deny policy before assertion/cleanup so bucket can be fully cleaned up
  - _Requirements: 1.9, 6.4, 6.5_

- [ ] 29.50 `e2e_warn_as_error`
  - **Tests**: `--warn-as-error` promotes warnings to errors
  - **Setup**: Upload 10 objects
  - **Config**: `--warn-as-error --force`
  - **Assertions**: Pipeline completes; if any warnings occurred, `has_error()` returns true; otherwise normal completion
  - _Requirements: 10.5_

## E2E Test Plan: AWS Configuration Tests

- [ ] 29.51 `e2e_target_region_override`
  - **Tests**: `--target-region` overrides profile region
  - **Setup**: Upload 10 objects in the default region
  - **Config**: `--target-region <same-region-as-bucket> --force`
  - **Assertions**: Pipeline completes; all 10 objects deleted (region override does not break access)
  - _Requirements: 8.5_

- [ ] 29.52 `e2e_target_force_path_style`
  - **Tests**: `--target-force-path-style`
  - **Setup**: Upload 10 objects
  - **Config**: `--target-force-path-style --force`
  - **Assertions**: Pipeline completes; all 10 objects deleted (path-style access works with standard S3)
  - _Requirements: 8.6_

- [ ] 29.53 `e2e_target_request_payer`
  - **Tests**: `--target-request-payer`
  - **Setup**: Upload 10 objects
  - **Config**: `--target-request-payer --force`
  - **Assertions**: Pipeline completes; all 10 objects deleted (request payer header does not break normal operations)
  - _Requirements: 8.3_

- [ ] 29.53a `e2e_allow_lua_unsafe_vm`
  - **Tests**: `--allow-lua-unsafe-vm` disables Lua sandbox entirely
  - **Setup**: Upload 5 objects. Write a Lua filter script that uses `os.clock()` (OS library function)
  - **Config**: `--filter-callback-lua-script <path> --allow-lua-unsafe-vm --force`
  - **Assertions**: Pipeline completes without Lua sandbox error; all 5 matching objects deleted (unsafe VM allows OS access)
  - _Requirements: 2.14_

## CLI Options Not Directly Testable in E2E

The following CLI options are NOT tested in E2E because they require infrastructure not available in standard E2E test environments:
- `--target-endpoint-url`: Requires a running S3-compatible service (MinIO/LocalStack). Out of scope for AWS E2E.
- `--target-accelerate`: Requires S3 Transfer Acceleration enabled on the test bucket. Out of scope.
- `--allow-parallel-listings-in-express-one-zone`: Requires Express One Zone directory bucket. Out of scope.
- `--auto-complete-shell`: Shell completion generator, not a runtime feature. Covered by unit tests.
- `--aws-config-file`, `--aws-shared-credentials-file`: Indirectly tested via `--target-profile s3rm-e2e-test` which uses the default credential file paths. Explicit path override testing is infrastructure-dependent.
- `--target-session-token`: Conflicts with `--target-profile`; implicitly covered by 29.48 (credential group). Testing with STS temporary credentials requires an STS assume-role setup.

## E2E Test Plan: Combined/Advanced Tests

- [ ] 29.54 `e2e_multiple_filters_combined`
  - **Tests**: Multiple filters combined with AND logic
  - **Setup**: Upload 30 objects: 10 with key `logs/small.txt` (100B), 10 with key `logs/large.txt` (10KB), 10 with key `data/large.dat` (10KB)
  - **Config**: `s3://{bucket}/logs/ --filter-include-regex "\\.txt$" --filter-larger-size 1KB --force`
  - **Assertions**: Only 10 `logs/large.txt` objects deleted (matching prefix AND regex AND size); 20 others remain
  - _Requirements: 2.11_

- [ ] 29.55 `e2e_dry_run_with_delete_all_versions`
  - **Tests**: Dry-run mode combined with `--delete-all-versions`
  - **Setup**: Create versioned bucket; upload 10 objects; overwrite each once (creates 20 versions total)
  - **Config**: `--dry-run --delete-all-versions --force`
  - **Assertions**: All 20 versions still exist (dry-run); stats show 20 "deleted" (simulated); no actual S3 deletions
  - _Requirements: 3.1, 5.2, 5.4_

- [ ] 29.56 `e2e_dry_run_with_filters`
  - **Tests**: Dry-run combined with filters accurately simulates filtered deletion
  - **Setup**: Upload 20 objects: 10 matching `^temp/`, 10 not matching
  - **Config**: `--dry-run --filter-include-regex "^temp/" --force`
  - **Assertions**: All 20 objects still exist; stats show 10 "deleted" (the matching ones)
  - _Requirements: 3.1, 2.2_

- [ ] 29.57 `e2e_max_delete_with_filters`
  - **Tests**: `--max-delete` interacts correctly with filters
  - **Setup**: Upload 50 objects: 30 matching `^to-delete/`, 20 not matching
  - **Config**: `--filter-include-regex "^to-delete/" --max-delete 5 --force`
  - **Assertions**: Exactly 5 of the `to-delete/` objects deleted; 25 `to-delete/` and 20 other objects remain
  - _Requirements: 3.6, 2.2_

- [ ] 29.58 `e2e_lua_filter_with_event_callback`
  - **Tests**: Lua filter callback combined with Lua event callback
  - **Setup**: Upload 20 objects. Write Lua filter (delete objects with size > 500B). Write Lua event script (log events to file, requires `--allow-lua-os-library`)
  - **Config**: `--filter-callback-lua-script <filter> --event-callback-lua-script <event> --allow-lua-os-library --force`
  - **Assertions**: Only objects > 500B deleted; event script output file contains expected events
  - _Requirements: 2.8, 2.12, 7.6_

- [ ] 29.59 `e2e_large_object_count`
  - **Tests**: Deleting close to the maximum allowed objects (1000)
  - **Setup**: Upload 1000 objects (each 1KB)
  - **Config**: `--force`
  - **Assertions**: All 1000 objects deleted; stats show 1000 deleted, 0 failed
  - _Requirements: 1.1, 1.8_

- [ ] 29.59a `e2e_all_filters_combined`
  - **Tests**: All filter types applied simultaneously with AND logic
  - **Setup**: Upload 20 objects with diverse properties (varied keys, sizes, content-types, metadata, tags). Only 3 objects satisfy every filter; the other 17 are each excluded by at least one filter.
  - **Filters**: prefix `data/`, `--filter-include-regex "\.json$"`, `--filter-exclude-regex "archive"`, `--filter-larger-size 500B`, `--filter-smaller-size 5KB`, `--filter-include-content-type-regex "application/json"`, `--filter-include-metadata-regex "env=production"`, `--filter-exclude-metadata-regex "retain=true"`, `--filter-include-tag-regex "deletable=yes"`, `--filter-exclude-tag-regex "protected=true"`, `--force`
  - **Assertions**: Exactly 3 objects deleted; 17 remain; each excluded group verified individually
  - _Requirements: 2.2, 2.3, 2.4, 2.5, 2.6, 2.11_

## E2E Test Plan: Statistics and Result Verification

- [ ] 29.60 `e2e_deletion_stats_accuracy`
  - **Tests**: `get_deletion_stats()` returns accurate counts and byte totals
  - **Setup**: Upload 15 objects of known sizes (e.g., 5 x 1KB, 5 x 2KB, 5 x 5KB = total 40KB)
  - **Config**: `--force`
  - **Assertions**: `stats.stats_deleted_objects == 15`; `stats.stats_deleted_bytes == 40960` (exact byte count); `stats.stats_failed_objects == 0`; `stats.duration > 0`
  - _Requirements: 6.5, 7.1, 7.3_

- [ ] 29.61 `e2e_event_callback_receives_all_event_types`
  - **Tests**: Event callback receives PIPELINE_START, DELETE_COMPLETE, STATS_REPORT, and PIPELINE_END
  - **Setup**: Upload 5 objects. Register Rust event callback collecting all events.
  - **Config**: `--force`
  - **Assertions**: Received exactly 1 PIPELINE_START, 5 DELETE_COMPLETE, at least 1 PIPELINE_END; DELETE_COMPLETE events contain key, size; PIPELINE_END event contains final stats
  - _Requirements: 7.6, 7.7_

## E2E Test Execution Instructions

```bash
# 1. Configure AWS credentials for the e2e test profile
aws configure --profile s3rm-e2e-test

# 2. Run all E2E tests
RUSTFLAGS="--cfg e2e_test" cargo test --all-features --test '*' -- --test-threads=8

# 3. Run a specific E2E test
RUSTFLAGS="--cfg e2e_test" cargo test --all-features --test e2e_basic -- e2e_basic_prefix_deletion

# WARNING: These tests create and delete real AWS S3 resources.
# Failed tests may leave behind buckets that need manual cleanup.
# Bucket names follow the pattern: s3rm-e2e-*
```

## E2E Test File Organization

```
tests/
+-- common/
|   +-- mod.rs             # TestHelper, bucket management, pipeline runner
+-- e2e_filter.rs          # Tests 29.1-29.12 (filtering)
+-- e2e_deletion.rs        # Tests 29.13-29.17 (core deletion modes)
+-- e2e_safety.rs          # Tests 29.18-29.20 (safety features)
+-- e2e_versioning.rs      # Tests 29.21-29.23 (versioning)
+-- e2e_callback.rs        # Tests 29.24-29.30 (Lua + Rust callbacks)
+-- e2e_optimistic.rs      # Tests 29.31-29.32a (if-match)
+-- e2e_performance.rs     # Tests 29.33-29.37 (performance options)
+-- e2e_tracing.rs         # Tests 29.38-29.44 (logging/tracing)
+-- e2e_retry.rs           # Tests 29.45-29.47 (retry/timeout options)
+-- e2e_error.rs           # Tests 29.48-29.50 (error handling, access denial)
+-- e2e_aws_config.rs      # Tests 29.51-29.53 (AWS config options)
+-- e2e_combined.rs        # Tests 29.54-29.59 (combined/advanced scenarios)
+-- e2e_stats.rs           # Tests 29.60-29.61 (statistics verification)
```

_Requirements: 1.1-1.11, 2.1-2.14, 3.1-3.6, 4.1-4.10, 5.1-5.5, 6.1-6.6, 7.1-7.7, 8.1-8.8, 10.1-10.7, 11.1-11.4, 12.1-12.9, 13.1-13.7_
